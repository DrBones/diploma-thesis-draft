\label{sec:rgapresentation}
The \emph{Recursive-\gfnc-Algorithm} (RGA) \cite{MacKinnon1985} is an optimized algorithm to compute the retarded \gfnc{}. It has been extended by the \textsc{Keldysh} equation to compute the lesser \gfnc{} $\mat{G}^<$ \cite{JApplPhys.91.2343}.
The RGA is based on the possibility that the \hamil{} can be written in a block tridiagonal form as described in \cref{sec:naruralordering}.
This form can be achieved for any system in the tight-binding approximation, each block representing a distinct section of the device \cite{Wimmer2009Thesis}.\par
% \todo{Complexity and implementation in Appendix \ref{app:RGA}, see Wimmer page 189}
Due to the fact that the electron and spin density only depend on certain elements of the \gfnc{} matrix the RGA computes those elements with only a little overhead. While still superfluous elements are computed the complexity is greatly reduced. The algorithm can be derived by the \textsc{Dyson} equation
\begin{align}
	\mat{G} = \mat{G}_0+\mat{G}_0\mat{U}\mat{G}\ .
	\label{eqn:DysonEquationG}
\end{align}
Here $\mat{G}_0$ denotes the \gfnc{} of the isolated block and $\mat{G}$ includes the remaining blocks and their interactions. The recursive calculation of connected blocks of the \gfnc{} matrix is obtained by the pertubation term $\mat{G}_0\mat{U}\mat{G}$. A more detailed derivation is outlined in Appendix \ref{app:RGA}.\par
For conduction, spin and electron densities, the retarded and lesser \gfnc s have to be computed. Because the computation of the lesser \gfnc{} is based on a prior computation of the retarded \gfnc{} the results of the former can be saved to obtain both \gfnc s.\par
In order to simplify the notation, the subscript $C$ will be dropped and the inverse of \cref{eqn:finitegreensfunctionwithselfenergy} can be written as
\begin{align}
(E\mathds{1}-\mat{H})\mat{G}_C = \mat{A}\mat{G}=\mathds{1}\ .
\label{eqn:amatrix}
\end{align}
with the \hamil{} $\mat{H}=\mat{H}_C +\mat{\Sigma}_{Ll}+\mat{\Sigma}_{Lr}+\mat{\Sigma}_{\text{scat}} $.
The central object in the recursive scheme to compute the retarded \gfnc{} is the left-connected \gfnc{} $\mat{G}^{r,i-1}$ containing all the blocks with index up to $i-1$ \cite{JApplPhys.91.2343}. Using the \textsc{Dyson} equation a link to $\mat{G}^{r,i}$ is established allowing the recursive evaluation of all blocks.\par
Let $\mat{G}=\mat{G}^{r,i-1}$ be the \gfnc{} for the connected blocks up to index $i-1$ (\cref{fig:rga1}) then $\mat{G}_0$ corresponds to the \gfnc{} for the blocks up to index $i-1$ plus the \emph{isolated} block $i$ (\cref{fig:rga2}). This system is described by the matrix
\begin{align}
\mat{A}_i = 
\begin{pmatrix}
\ddots 	& \vdots 	   & 		   & \\
\dots   & \mat{A}_{i-2,i-2}&\mat{A}_{i-2,i-1}& \\
     	& \mat{A}_{i-1,i-2}  &\mat{A}_{i-1,i-1}  & \mat{0} \\ 
	&  		   & \mat{0} 	   & \mat{A}_{i,i}
\end{pmatrix}\ .
\end{align}
Diagonal blocks $\mat{A}_{i,i} = E\mathds{1}-\mat{H}_{i,i}$ describe each isolated section and the off-diagonal blocks the interactions between neighboring sections. The isolated block is attached to the rest of the matrix via the \emph{hopping matrices} (\cref{fig:rga3})
\begin{align}
\mat{U} = 
\begin{pmatrix}
\mat{0}& -\mat{A}_{i-1,i}\\
-\mat{A}_{i,i-1}&\mat{0}
\end{pmatrix}\ .
\label{eqn:umatrix}
\end{align}
When inserting \cref{eqn:umatrix} into \cref{eqn:DysonEquationG} the recursive relation between block $i$ and $i+1$ reads 
\begin{align}
\mat{G}^{r,i}_{i,i} := \left[\mat{A}_{i,i}-\mat{A}_{i,i-1}\mat{G}^{r,i-1}_{i-1,i-1}\mat{A}_{i-1,i}\right]^{-1}\ .
\label{eqn:rga}
\end{align}
With analogous calculations the relations between diagonal and off-diagonal parts  of the \gfnc{} 
\begin{align}
\mat{G}^r_{i,i-1} &= -\mat{G}^r_{i,i}\mat{A}_{i,i-1}\mat{G}^{r,i-1}_{i-1,i-1}\\
\mat{G}^r_{i-1,i} &= -\mat{G}^{r,i-1}_{i-1,i-1}\mat{A}_{i-1,i} \mat{G}^{r}_{i,i}\\
\mat{G}^r_{i-1,i-1} &= \mat{G}^{r,i}_{i-1,i-1}-\mat{G}^{r,i-1}_{i-1,i-1}\mat{A}_{i-1,i}\mat{G}^{r}_{i,i-1}\ .
\end{align}
can be found enabling the computation of all matrix blocks.\par
It is important to note that not all matrix elements can be calculated during one pass of the algorithm. After calculation of the first left-connected \gfnc{} at the starting lead $i=0$ \cref{eqn:rga} is used successively until the other lead at index $i=N$ is reached. The $N$th element of the left connected \gfnc{} is already identical to the $N$th element of the full retarded \gfnc{}. The influence of the final lead needs to be propagated to all prior slices. This is done in a \emph{backward pass} during which all desired blocks can be computed, see \cref{alg:retardedrga}.\par
\begin{figure}
\subfloat[]{\label{fig:rga1}\begin{tikzpicture}\node at (0,0)[above] {\includegraphics[width=0.28\textwidth]{images/rga1.pdf}};
\node at (0,4) {$G^{r,i-1}$};
\node at (0,-0.3) {$i-1$};
\node at (-1.8,-0.3) {$i-3$};
\end{tikzpicture}}\quad
\subfloat[]{\label{fig:rga2}\begin{tikzpicture}\node at (0,0)[above]{\includegraphics[width=0.28\textwidth]{images/rga2.pdf}};
\node at (0,4) {$G_0$};
\node at (0,-0.3) {$i-1$};
\node at (1.8,-0.3) {$i$};
\node at (-1.8,-0.3) {$i-3$};
\node[font=\Large] at (1,1.8) {+};
\end{tikzpicture}}\quad
\subfloat[]{\label{fig:rga3}\begin{tikzpicture}\node at (0,0)[above]{\includegraphics[width=0.28\textwidth]{images/rga3.pdf}};
\node at (0,4) {$G^{r,i}$};
\node at (0,-0.3) {$i-1$};
\node at (1,-0.3) {$i$};
\node at (-1.8,-0.3) {$i-3$};
\end{tikzpicture}}
\caption{Schematic of the recursive \gfnc{} algorithm. (a) Slices connected up to index i-1. (b) The \gfnc{} $\mat{G}_0$ of the blocks up to $i-1$ plus the isolated \gfnc{} at index $i$. (c) The isolated block is connected and the \gfnc{} $\mat{G}^{r,i}$ is obtained.}
\label{fig:rgaschematic}
\end{figure}
\vskip 1em
\noindent\begin{minipage}{\textwidth}
\begin{algo}\label{alg:retardedrga}
\textit{Recursive Algorithm for $\mat{G}^r$}\\
\begin{tabularx}{\textwidth}{l X l}
\addlinespace \cmidrule(r{1.2cm}){1-1}\addlinespace
  $\mat{G}^{r,0}_{0,0} := \mat{A}_{0,0}^{-1}$&& $\blacktriangleright$ initialize first element\\\addlinespace[12pt]
  \textbf{for} $i = 1:N-1$ \textbf{do} && \multirow{3}{45mm}{$\blacktriangleright$ recursively compute\\\hspace{10pt} left-connected\\\hspace{10pt} \gfnc{}}\\
  \qquad$\mat{G}^{r,i}_{i,i} := \left[\mat{A}_{i,i}-\mat{A}_{i,i-1}\mat{G}^{r,i-1}_{i-1,i-1}\mat{A}_{i-1,i}\right]^{-1}$&& \\
  \textbf{end for} 			&& \\\addlinespace[12pt]
  $\mat{G}^r_{N,N} := \mat{G}^{r,N}_{N,N}$   	&&$\blacktriangleright N$-th element found\\ \addlinespace[12pt]
  \textbf{for} $i = N-1:1$ \textbf{do}&&$\blacktriangleright$ backward pass\\
  \qquad$\mat{G}^r_{i,i-1} := -\mat{G}^r_{i,i}\mat{A}_{i,i-1}\mat{G}^{r,i-1}_{i-1,i-1}$  \tikz \node[coordinate,yshift=1em,xshift=11.3em] (n1) {}; && \multirow{2}{45mm}{\hspace{10pt} off-diagonal elements}\\ \addlinespace
  \qquad$\mat{G}^r_{i-1,i} := -\mat{G}^{r,i-1}_{i-1,i-1}\mat{A}_{i-1,i} \mat{G}^{r}_{i,i}$ \tikz \node[coordinate,xshift=11.3em] (n2) {}; && \\ \addlinespace
  \qquad$\mat{G}^r_{i-1,i-1} := \mat{G}^{r,i}_{i-1,i-1}-\mat{G}^{r,i-1}_{i-1,i-1}\mat{A}_{i-1,i}\mat{G}^{r}_{i,i-1}$   & &$\blacktriangleright$ diagonal elements \\ 
  \textbf{end for}&& \\\addlinespace \bottomrule 
\end{tabularx}
\end{algo}
\begin{tikzpicture}[overlay]
      \path (n2) -| node[coordinate] (n3) {} (n1);
      \draw[line width=1.5pt,decorate,decoration={brace,amplitude=5pt}]
            (n1) -- (n3) node[midway, right=4pt] {};
\end{tikzpicture}
\end{minipage}
The recursive computation of the lesser \gfnc{} follows the same concept starting from the \textsc{Keldysh} equation (\ref{eqn:keldyshequation}) for non-interacting systems rewritten as
\begin{align}
\mat{G}^<_{i,j} = \mat{G}^r_{i,0}\mat{\Sigma}^<_L(\mat{G}^r_{j,0})^{\dagger}+\mat{G}^r_{i,N+1}\mat{\Sigma}^<_R(\mat{G}^r_{j,N+1})^{\dagger}\ .
\end{align}
Here $\mat{\Sigma}^<_L$ and $\mat{\Sigma}^<_R$ denote the lesser self-energy term for the left and right lead. For the computation of the lesser \gfnc{} it is sufficient to compute diagonal and one off-diagonal of the retarded \gfnc{} $\mat{G}^r$. The algorithm to compute the lesser \gfnc{} is illustrated in \cref{alg:lesserrga}, with $\mat{\sigma}^<_i=\mat{A}_i\mat{G}^{<,i-1}_{i-1,i-1}\mat{A}^{\dagger}_i$. It requires a forward and a backward pass like the algorithm for the retarded \gfnc{}.\par
\vskip 1em
\noindent\begin{minipage}{\textwidth}
\begin{algo}\label{alg:lesserrga} 
\textit{Recursive Algorithm for $\mat{G}^<$}\\
\begin{tabularx}{\textwidth}{l l}
\addlinespace\cmidrule(r{3.5cm}){1-1}\addlinespace
 $\mat{G}^{<,0}_{0,0} := \mat{G}^{r,0}_{0,0}\mat{\Sigma}^<_{0,0} \mat{G}^{a,0}_{0,0}$& $\blacktriangleright$ initialize first element\\\addlinespace[12pt]
 \textbf{for} $i = 1:N-1$ \textbf{do} & \multirow{3}{45mm}{$\blacktriangleright$ recursively compute\\\hspace{10pt} left-connected\\\hspace{10pt} \textsc{Green}'s function}\\
 \qquad$\mat{G}^{<,i}_{i,i} := \mat{G}^{r,i}_{i,i}( \mat{\Sigma}^<_{i,i}+\mat{\sigma}^<_{i})\mat{G}^{a,i}_{i,i}$& \\
 \textbf{end for} 				& \\\addlinespace[12pt]
 $\mat{G}^<_{N,N} := \mat{G}^{<,N}_{N,N}$   	&$\blacktriangleright N$-th element found \\ \addlinespace[12pt]
 \textbf{for} $i = N-1:1$ \textbf{do} 	  	&$\blacktriangleright$ backward pass\\
 \qquad$\mat{G}^<_{i,i-1} := \mat{G}^r_{i,i}\mat{A}_{i,i-1}\mat{G}^{<,i-1}_{i-1,i-1} +\mat{G}^<_{i,i}\mat{A}^{\dagger}_{i,i-1}\mat{G}^{a,i-1}_{i-1,i-1}$ &$\blacktriangleright$ off-diagonal elements\\ \addlinespace
 \qquad$\mat{G}^<_{i-1,i-1} := \mat{G}^{<,i-1}_{i-1,i-1} +\mat{G}^{r,i-1}_{i-1,i-1}(\mat{A}_{i-1,i}\mat{G}^{<}_{i,i}\mat{A}^{\dagger}_{i,i-1})\mat{G}^{a,i-1}_{i-1,i-1}$ &$\blacktriangleright$ diagonal elements \\ \addlinespace
 \hspace{4.5cm}$ + \mat{G}^{<,i-1}_{i-1,i-1}\mat{A}^{\dagger}_{i-1,i}\mat{G}^a_{i,i-1}$&\\\addlinespace
 \hspace{4.5cm}$+\mat{G}^r_{i-1,i}\mat{A}_{i,i-1}\mat{G}^{<,i-1}_{i-1,i-1}$&\\ 
 \textbf{end for}& \\\addlinespace \bottomrule 
\end{tabularx}
\end{algo}
\end{minipage}
\subsection{Computational Complexity of RGA}\label{sec:rgacomplexity}
The most demanding operations of the algorithms are the matrix multiplication and inversion. Both operations scale $\mathcal{O}(N^3)$ with the size of the involved $N \times N$ matrices. As the algorithms carry out a constant number of operations per block the overall RGA scales as $\mathcal{O}(N^3M)$ with $M$ being the number of blocks\,\cite{Li2009Thesis}.\par
For an elongated device that is much longer in the $x$ than in the $y$ direction, the number of lattice points in that direction is larger than the other ($N_y \ll N_x$). On a simple square lattice this amounts to a running time order of $\mathcal{O}(N_y^3N_x)$  instead of the direct approach $\mathcal{O}(N_y^3N_x^3=\text{Number of lattice-points})$.\par
The reduced complexity is based on the selective computation of matrix blocks if all entries of $\mat{G}$ were required the computational cost would also be $\mathcal{O}(N_y^3N_x^3)$.
\FloatBarrier
